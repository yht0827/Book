# 서버 성능 개선 가이드

## 개요

성능 저하의 가장 눈에 띄는 현상은 **결과가 늦게 표시되는 것**입니다. 서버 성능과 관련된 핵심 지표는 **응답 시간**과 **처리량** 2가지입니다.

---

## 1. 성능 핵심 지표

### 1.1 응답 시간 (Response Time)

사용자의 요청을 처리하는 데 걸리는 시간을 의미합니다.

**클라이언트 → 서버 요청 과정:**
1. **서버에 연결**: TCP를 이용해 서버 연결
2. **데이터 전송**: HTTP 프로토콜에 따라 데이터 전송 (예: POST, JSON)

**응답 시간 측정 방식:**
- **TTFB (Time To First Byte)**: 첫 번째 바이트 도착까지 걸린 시간
- **TTLB (Time To Last Byte)**: 마지막 바이트 도착까지 걸린 시간
- 응답 데이터가 작으면 TTFB ≈ TTLB
- 파일 다운로드처럼 데이터가 크거나 네트워크가 느리면 차이 발생

**응답 시간 구성 요소:**
```
응답 시간 = API 요청 전송 시간 + 서버 처리 시간 + API 응답 전송 시간
```

**서버 처리 시간 세부 요소:**
- 로직 수행 (if, for 등)
- **DB 연동** (SQL 실행) ← 큰 비중
- **외부 API 연동** ← 큰 비중
- 응답 데이터 생성

### 1.2 처리량 (Throughput)

단위 시간당 시스템이 처리하는 작업량을 의미합니다.

**측정 단위:**
- **TPS (Transaction Per Second)**: 초당 트랜잭션 수
- **RPS (Request Per Second)**: 초당 요청 수

**예시:**
```
서버가 한 번에 5개 요청 처리 가능 (요청당 1초 소요)
→ 최대 TPS = 5
→ 동시 요청 > 5 → 초과 요청은 대기
```

**처리량 향상 방법:**
1. **동시 처리 가능한 요청 수 증가** → 서버 스펙 확장으로 TPS 증가
2. **처리 시간 자체 감소** → 요청당 처리 시간 단축으로 TPS 증가

**TPS 확인 도구:**
- Scouter, Pinpoint, New Relic 등 모니터링 시스템 활용

---

## 2. 성능 문제 진단

### 2.1 전형적인 증상

성능 문제는 트래픽 증가와 데이터 축적으로 점차 나타납니다.

**주요 증상:**
- 순간적으로 모든 요청의 응답이 심각하게 느려짐 (10초 이상)
- 다수의 요청에서 연결 시간 초과 오류 발생
- 서버 재시작 시 잠시 괜찮다가 다시 느려지는 현상 반복
- 트래픽이 줄어들 때까지 계속 악화

### 2.2 성능 문제 해결 프로세스

1. **병목 지점 식별**: 모니터링 도구 또는 로그 활용
2. **빠른 개선안 도출**: 수직/수평 확장 결정
3. **적용 및 모니터링**: 효과 측정

**모니터링이 없다면:**
```java
// 의심되는 코드의 실행 시간 로그 남기기
long startTime = System.currentTimeMillis();
// ... 비즈니스 로직
long duration = System.currentTimeMillis() - startTime;
log.info("API 실행 시간: {}ms", duration);
```

---

## 3. 서버 확장 전략

### 3.1 수직 확장 (Scale-Up)

CPU, 메모리, 디스크 등의 자원을 증가시키는 방법입니다.

**장점:**
- 빠르게 적용 가능
- 즉각적인 성능 향상

**단점:**
- 비용이 많이 듦 (고스펙 하드웨어는 가격 급상승)
- 지속적인 트래픽 증가 시 한계 존재
- 반복적인 확장 불가능

### 3.2 수평 확장 (Scale-Out)

동일 스펙의 서버를 추가로 투입해 TPS를 높이는 방법입니다.

**주의사항:**
```
❌ 잘못된 확장 사례:
- DB에서 성능 문제 발생 → 서버 추가 → DB 부하 증가 → 악화
- 외부 API 성능 문제 → 서버 추가 → TPS 향상 없음
```

**올바른 접근:**
1. 실제 병목 지점 파악
2. 병목 지점에 맞는 확장 전략 수립
3. 로드 밸런서를 통한 부하 분산 고려

---

## 4. DB 커넥션 풀 최적화

### 4.1 DB 커넥션 풀이란?

DB 연결을 미리 생성해두고 재사용하는 방식입니다.

**필요성:**
- 매 요청마다 DB 연결/종료 시 성능 저하
- 트래픽 증가 시 처리량 급격히 감소
- Spring Boot는 HikariCP를 기본 커넥션 풀로 사용

### 4.2 커넥션 풀 크기 설정

**기본 개념:**
```
커넥션 풀 크기 < 동시 요청 수
→ 커넥션 대기 발생
→ 응답 시간 증가
```

**크기 결정 시 고려사항:**
- 전체 응답 시간
- TPS
- DB 서버 상태 (특히 CPU 사용률)

**주의:**
```
❌ DB CPU 사용률 80% 상황에서 커넥션 풀 크기 증가
→ DB 부하 증가
→ 쿼리 실행 시간 급증
```

### 4.3 커넥션 대기 시간 (Connection Timeout)

커넥션을 얻기 위해 기다릴 수 있는 최대 시간입니다.

**설정 전략:**
```
짧은 대기 시간 설정:
✅ 에러는 발생하지만 서버 부하 일정 수준 유지
✅ 안정적인 서비스 운영 가능

긴 대기 시간 설정:
❌ 응답 시간 증가
❌ 서버 부하 급증 가능
```

### 4.4 기타 설정

**최대 유휴 시간 (Max Idle Time):**
- 사용되지 않는 커넥션을 풀에 유지할 수 있는 최대 시간

**유효성 검사 (Validation Query):**
```sql
SELECT 1 FROM dual
SELECT 1
```
- 커넥션이 정상 동작하는지 확인

**최대 유지 시간 (Max Lifetime):**
- 커넥션이 생성된 시점부터 풀에 유지될 수 있는 최대 시간

---

## 5. 캐시 전략

### 5.1 캐시 필요성

DB 서버 확장 없이 응답 시간과 처리량을 개선할 수 있는 방법입니다.

**장점:**
- DB 확장 대비 적은 비용
- 개발자/인프라 엔지니어 부담 적음

**단점:**
- 코드 수정 필요

### 5.2 적중률 (Hit Rate)

캐시 효율성을 판단하는 지표입니다.

```
적중률 = 캐시에 존재한 건수 / 캐시 조회 시도 건수

예시: 100번 조회 중 87번 존재 → 적중률 87%
```

### 5.3 캐시 삭제 규칙

캐시가 가득 찰 경우 데이터 삭제 방식입니다.

**주요 규칙:**
- **LRU (Least Recently Used)**: 가장 오랫동안 사용되지 않은 데이터 삭제
- **LFU (Least Frequently Used)**: 가장 적게 사용된 데이터 삭제
- **FIFO (First In First Out)**: 가장 먼저 들어온 데이터 삭제

**실무 선택:**
대부분 서비스에서 최신 데이터를 더 자주 조회 → **LRU 추천**

### 5.4 로컬 캐시 vs 리모트 캐시

#### 로컬 캐시 (In-Memory Cache)

서버 프로세스와 동일한 메모리를 사용합니다.

**장점:**
- 빠른 접근 속도 (메모리 직접 접근)
- 단순한 구조 (외부 연동 불필요)

**단점:**
- 저장 가능한 데이터 크기 제한
- 서버 재시작 시 캐시 데이터 손실 → 적중률 일시적 하락

#### 리모트 캐시 (Remote Cache)

별도 프로세스를 캐시 저장소로 사용합니다 (예: Redis).

**장점:**
- 유연한 확장 가능 (Redis Cluster)
- 서버 재시작 시에도 캐시 데이터 유지

**단점:**
- 네트워크 통신 오버헤드 (로컬 캐시 대비 느림)
- 시스템 구조 복잡도 증가
- 별도 서버 장비 필요

**비교 표:**
| 구분 | 로컬 캐시 | 리모트 캐시 |
|------|----------|------------|
| 속도 | 빠름 | 상대적으로 느림 |
| 확장성 | 제한적 | 유연함 |
| 데이터 유지 | 재시작 시 손실 | 재시작 시 유지 |
| 구조 | 단순 | 복잡 |
| 비용 | 낮음 | 높음 |

### 5.5 캐시 사전 적재 (Cache Warming)

트래픽이 순간적으로 급증하는 패턴을 보인다면 데이터를 미리 캐시에 저장합니다.

**적용 사례:**
- 이벤트 시작 직전
- 배치 작업 완료 후
- 서버 재시작 직후

### 5.6 캐시 무효화 (Cache Invalidation)

유효하지 않은 데이터를 적절한 시점에 캐시에서 삭제합니다.

**중요성:**
```
원본 변경 → 캐시 미갱신 → 사용자가 오래된 정보 조회
```

**전략:**
- TTL (Time To Live) 설정
- 원본 변경 시 즉시 캐시 삭제
- 이벤트 기반 무효화

---

## 6. 메모리 최적화

### 6.1 가비지 컬렉션 고려

**문제:**
- 메모리 사용량 증가 → GC 시간 증가
- 대량 객체 생성 → GC 부담 증가

**해결책:**
1. 조회 범위 제한
2. 한 번에 조회할 수 있는 데이터 개수 제한
3. 페이지네이션 적용

### 6.2 스트림 활용

**잘못된 예시:**
```java
// 파일을 한 번에 메모리에 로딩
byte[] bytes = Files.readAllBytes(Paths.of("path"));
out.write(bytes);

/*
30MB 파일 × 100명 동시 다운로드 = 약 3GB 메모리 필요
*/
```

**개선된 예시:**
```java
// 8KB씩 읽어서 처리
InputStream is = Files.newInputStream(Path.of("path"));
byte[] buffer = new byte[8192]; // 8KB
int read;
while ((read = is.read(buffer, 0, 8192)) >= 0) {
    out.write(buffer, 0, read);
}
// 또는 is.transferTo(out) 사용

/*
100명 동시 다운로드 → 약 800KB 메모리만 필요
*/
```

---

## 7. 네트워크 최적화

### 7.1 응답 데이터 압축

**압축 대상:**
- HTML, CSS, JavaScript, JSON (텍스트 데이터)

**효과:**
- gzip 압축 시 70% 이상 크기 감소
- 전송 시간 단축
- 클라우드 환경에서 비용 절감 (트래픽 = 비용)

**압축 프로세스:**
```
1. 클라이언트 요청:
   Accept-Encoding: gzip, deflate

2. 서버 응답:
   Content-Encoding: gzip
   [압축된 데이터]
```

**주의사항:**
- JPEG 이미지, ZIP 파일 등 이미 압축된 데이터는 효과 없음
- 방화벽이 압축을 해제할 수 있음

### 7.2 정적 자원과 브라우저 캐시

**문제:**
정적 자원(이미지, JS, CSS)이 전체 트래픽의 80% 차지 가능

**해결:**
브라우저 캐시 활용으로 트래픽 감소

**HTTP 헤더 설정:**
```
Cache-Control: max-age=31536000
Expires: Thu, 31 Dec 2025 23:59:59 GMT
```

### 7.3 CDN (Content Delivery Network)

**필요성:**
브라우저 캐시는 브라우저 단위로만 동작 → 동시 접속자 증가 시 한계

**CDN 서비스:**
- Amazon CloudFront
- Cloudflare
- Akamai

**장점:**
- 지역별 분산 서버로 빠른 콘텐츠 제공
- 원본 서버 부하 감소
- 트래픽 비용 절감

---

## 8. 트래픽 제어

### 8.1 대기 처리 (Queueing)

무작정 서버/DB 증설하는 대신 수용 가능한 트래픽만 받아들이는 방법입니다.

**장점:**
- 서버 증설 없이 안정적인 서비스 제공
- 불필요한 새로 고침 방지 (순번이 뒤로 밀림)

**적용 사례:**
- 티켓팅 서비스
- 한정판 상품 판매
- 이벤트 응모

**구현 방식:**
```
사용자 → 대기열 진입 → 순번 부여 → 차례대로 처리
```

## 요약

**성능 개선 우선순위:**
1. **병목 지점 식별** (모니터링 필수)
2. **빠른 개선** (수직 확장, 인덱스 추가)
3. **캐시 도입** (로컬 → 리모트)
4. **DB 최적화** (커넥션 풀, 쿼리 개선)
5. **수평 확장** (로드 밸런서 + 서버 추가)
6. **네트워크 최적화** (압축, CDN)

**핵심 원칙:**
- 항상 측정하고 모니터링할 것
- 병목 지점을 정확히 파악한 후 개선할 것
- 트레이드오프를 고려할 것 (비용, 복잡도, 효과)